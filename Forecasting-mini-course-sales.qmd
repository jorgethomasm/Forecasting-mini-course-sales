---
title: "Forecasting Sales Time-Series with XGBoost"
subtitle: "Sale Products: Kaggle's mini-courses." # only for html output
author: "Jorge A. Thomas"
date: "`r Sys.Date()`"
format:    
    html:
      self-contained: true
      code-fold: true
      df-print: tibble
      code-summary: "Show the code"
      grid: 
        margin-width: 350px
execute: 
  echo: fenced
reference-location: margin # margin
citation-location: document
bibliography: minicoursesales.bib
# Template: https://quarto-dev.github.io/quarto-gallery/page-layout/tufte.html
---

## Introduction

Here I present my solution to Kaggle's competition **Forecasting Mini-Course Sales** of 2023. 

Playground Series - Season 3, Episode 19.

Using the synthetic-generated dataset [@playground-series-s3e19], you'll follow my workflow developing pipelines on the ETL phase of the Data Science cycle using the R programming language [@R-base], as well as a tidy approach to forecasting.

::: {.callout-note appearance="simple"}
There was an error of the Kaggle team generating the target values of the test set in this synthetic dataset. Good forecast with the public dataset, i.e., train data deviates from the submission (test) results.
**This means that the best competition results are wrong!**
For details read: https://www.kaggle.com/competitions/playground-series-s3e19/discussion/425538

:::


```{r}
#| label: setup
#| message: false
#| echo: false
#| warning: false

library(tidyverse) # ETL and EDA tools
library(fpp3)  # Forecasting tools
library(urca)  # Unit Root and Cointegration Tests for Time Series Data
library(tictoc) # measure runtime
library(httpgd)

source("./libs/jthomfuncs.r")
theme_set(jthomggtheme)
```



```{r}
#| label: Load Data
#| warning: false

sales_train_raw <- read_csv("./data/raw/train.csv") # Train, validattion and test dataset
print("Dimensions of training dataset")
dim(sales_train_raw)

sales_test_raw <- read_csv("./data/raw/test.csv")  # Features for submission dataset
print("Dimensions of test dataset containing only Feats.")
dim(sales_test_raw) 

# Add Target column with NA so both DFs can be concatenated:.id
sales_test_raw <- 
  sales_test_raw |> 
    mutate(num_sold = NA)

# Binding and adding identifier column "dataset" 
sales_all <- 
  bind_rows(list(train = sales_train_raw, test = sales_test_raw), .id = "dataset")

print("Available variables:")
names(sales_all)

```

### Count NAs

```{r}
#| label: Counting NAs
#| code-fold: true

sales_all |>
  select(-num_sold) |>
  count_na() |>
  knitr::kable(caption = "Courses Sales dataset")

```

### Adding temporal features

```{r}

#' make a function of this!
#' expand_temporal_feats(datetime_colname)

sales_all <- sales_all |>
  mutate(year = year(date)) |>
  mutate(quarter = ceiling(month(date)/3)) |>
  mutate(month = month(date)) |>
  mutate(month_day = mday(date)) |>
  mutate(dow = wday(date, label = TRUE, abbr = FALSE)) |>
  mutate(is_weekend = weekdays(date)  %in% c("Saturday", "Sunday"))

# Delete "Using LLMS to " from product col

sales_all <- sales_all |>
  mutate(product = str_remove(product, "Using LLMs to ")) 


# Establish categorical variables
# Here these are actually "keys" to specify a single time-series

sales_all <- sales_all |>
  mutate(country = factor(country)) |>
  mutate(store = factor(store)) |>
  mutate(product = factor(product)) 

# cat_feats <- c("country", "store", "product")
# cat_feats <- sales_all |>
#   mutate(across(all_of(cat_feats), ~ factor(.x, ordered = FALSE)))

```

### Visualise Total Sales

#### Total Sales per Country
```{r}
#| warning: false

# country_colours = c("Argentina" = "#6CACE4", "Canada" = "#D80621", "Estonia" =  "#0072CE", "Japan" = "#636B2F", "Spain" = "#F1BF00")
country_colours = c("#6CACE4", "#D80621", "#0072CE", "#636B2F", "#F1BF00")
names(country_colours) <- levels(sales_all$country)

sales_all |> 
  filter(dataset == "train") |>
  group_by(country) |>
  summarise(total_sales = sum(num_sold)) |>
  ggplot(aes(y = fct_reorder(country, total_sales), x = total_sales)) + 
  geom_col(aes(fill = country)) +
  geom_text(aes(label = total_sales), size = 4) +
  labs(y = "Country", x = "Total Sales") + 
  scale_fill_manual(values = country_colours) +
  theme(legend.position = "none", axis.title.y = element_text(angle = 90))
 
# "%b %d" "%a %d %m %R"

# sales_all |> 
#   filter(dataset == "train") |>
#   group_by(date, country) |>
#   summarise(total_sales = sum(num_sold)) |>
#   mutate(year = as.factor(year(date))) |>

#   ggplot(aes(x = date, y = total_sales)) +
#   labs(x = "", y = "Total\nSales") +
#   geom_line() +
#   scale_x_date(date_breaks = "1 month", date_labels = "%b") + 
#   scale_y_continuous(breaks = seq(0, 8000, 1000)) + 
#   facet_grid(country ~ year, scales = "free_x") + 
#   # scale_fill_manual(values = country_colours) +
#   theme(axis.text.x  = element_text(angle = 90, size = 10) )

```

#### Most Popular Courses 

```{r}

sales_all |> 
  filter(dataset == "train") |>
  group_by(product) |>
  summarise(total_sales = sum(num_sold)) |>
  ggplot(aes(y = fct_reorder(product, total_sales), x = total_sales)) + 
  geom_col(aes(fill = product)) +
  geom_text(aes(label = total_sales), size = 4) +
  labs(title = "Using LLMs to..." ,y = "Product (Mini-Course)", x = "Total Sales") + 
  theme(legend.position = "none", axis.title.y = element_text(angle = 90))
```

It seems that LLMs are not that useful to win friends and influence people...

#### Response Analysis (Sales)

Here I check the distribution of the target variable in general.

```{r}

sales_all |>
  filter(dataset == "train") |>
  group_by(date) |>
  summarise(total_sales = sum(num_sold)) |>

  ggplot(aes(x = total_sales)) +  
  geom_histogram(bins = 35, color = "red", fill = "red", alpha = 0.5) +
  # scale_x_continuous(breaks = seq(0, 800, 50), labels = scales::comma) +  
  labs(x = "Sold Mini-Courses")

```

#### Time-Series: Total Sales (Aggregated Sum)

```{r}
#| warning: false

sales_all |> 
  filter(dataset == "train") |>
  group_by(date) |>
  summarise(total_sales = sum(num_sold)) |>
  mutate(year = as.factor(year(date))) |>

  ggplot(aes(x = date, y = total_sales)) +
  labs(x = "", y = "Total\nSales") +
  geom_line(colour = "red") +
  scale_x_date(date_breaks = "1 month", date_labels = "%b") + 
  scale_y_continuous(breaks = seq(0, 24000, 2000)) + 
  facet_wrap(~year, scales = "free_x", nrow = 1) +    
  theme(axis.text.x  = element_text(angle = 90, size = 8))
```

#### Time-Series: Total Sales per Country

```{r}
#| warning: false

sales_all |> 
  filter(dataset == "train") |>
  group_by(date, country) |>
  summarise(total_sales = sum(num_sold)) |>
  pivot_wider(names_from = country, values_from = total_sales) |>
  
  ggplot(aes(x = date)) +
  labs(x = "", y = "Total\nSales") +
  geom_line(aes(y = Argentina), colour = "#6CACE4") +
  geom_line(aes(y = Canada), colour = "#D80621") +
  geom_line(aes(y = Estonia), colour = "#0072CE") +
  geom_line(aes(y = Japan), colour = "#636B2F") +
  geom_line(aes(y = Spain), colour = "#F1BF00") +
  scale_x_date(date_breaks = "1 years", date_minor_breaks = "6 months", date_labels = "%Y") + 
  scale_y_continuous(breaks = seq(0, 8000, 1000)) 
```

- The effects of the **pandemic** are clear, more stronlgy during the lock-down period.
- During the last week of every year, i.e., christmas holidays, sales spike. 

### Add Pandemic and Holidays Flags

One can see clearly the pandemic effect starting on March 2020. A feature flag should be added.

```{r}
sales_all$pandemy <- FALSE
sales_all$pandemy[which(sales_all$year == 2020)] <- TRUE

sales_all$holiday <- FALSE
sales_all$holiday[which(sales_all$month == 12 & sales_all$month_day > 23)] <- TRUE
```

#### Time-Series: Total Sales per Product

```{r}

# sales_all |> 
#   filter(dataset == "train") |>
#   group_by(date, product) |>
#   summarise(total_sales = sum(num_sold)) |>
#   pivot_wider(names_from = product, values_from = total_sales) |> 

#   ggplot(aes(x = date, y = num_sold)) +
#   labs(x = "", y = "Total\nSales") +
#   geom_line() +
#   scale_x_date(date_breaks = "1 years", date_minor_breaks = "6 months", date_labels = "%Y") + 
#   scale_y_continuous(breaks = seq(0, 6000, 1000)) +

#   facet_grid(date ~ product, scales = "free_x") + 
#   # scale_fill_manual(values = country_colours) +
#   theme(axis.text.x  = element_text(angle = 90, size = 10) )


```

## Define a tsibble object

Considering that *country*, *store*, and *product* are keys, there are 75 time-series in total to model.

```{r}

sales <- sales_all |>
  filter(dataset == "train") |>  
  select(-c("id", "dataset")) |>
  as_tsibble(key = c(country, store, product), index = date) 

# tsibble::interval(sales)
# tsibble::is_regular(sales)

sales

# Train (fit) models

tic("Training ARIMA")

sales_fit <- sales |>  model(arima = ARIMA(num_sold)) 

toc()

# sales_fit <- sales |>  model(ets = ETS(num_sold), arima = ARIMA(num_sold)) |> mutate(ensemble = (ets + arima)/2)

#left_join

```



```{r}
#| label: forecast

# sales_fc <- sales_fit |> forecast(h = "1 years")


# Vis


```